{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Code for Blunt Malacology's Phylogenetic Pipeline**\n",
    "\n",
    "This is a set of markdown where each of the cells are supposed to be run at each level. To use, create a file system, them move things across as needed.\n",
    "\n",
    "The settings provided are a default set, which can be consulted in the code as and when needed.\n",
    "\n",
    "| Standard csv file formats  | | | | |\n",
    "|-----------|---------|---------|-|-|\n",
    "| **Ascension file** | Taxon | Gene1 | Gene2 | ... |\n",
    "| **Enum file** | Enum_id | Taxon |||\n",
    "| **Description file** | Enum_id | Taxon | Ascension_number | Taxon_description |\n",
    "| **Gene length** | Gene | Length | | |\n",
    "\n",
    "**Standard fasta format for genes:**\n",
    "\n",
    ">\\><enum_id> Genus_species<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ACTG...\n",
    "\n",
    "#### Metadata for the environment\n",
    "Uses Visual Studio version .\n",
    "& Python 3.9.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"tags\": [\n",
    "        \"hide-input\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "\"\"\" Forms a checkpoint\n",
    "Prints the checkpoint position out of a total number\n",
    "*TODO MAY CHANGE TO PERCENTAGE*\n",
    "TODO Clears the string buffer beforehand\n",
    "\n",
    "returns the next checkpoint number\n",
    "\"\"\"\n",
    "def checkpoint(head,count,tot = 0,remove=True):\n",
    "    to_log = \"\"\n",
    "    to_log += \"\\t\" + head + \": checkpoint \" + str(count)\n",
    "    if (tot != 0):\n",
    "        to_log += \"/\" + str(tot)\n",
    "    print(to_log)\n",
    "\n",
    "    return count+1\n",
    "\n",
    "import csv\n",
    "\n",
    "\"\"\"\n",
    "Create enumerated file\n",
    "\n",
    "/param ascension_filename - a string of the csv input_ascensions file to open & create the enumerated file for\n",
    "    in the form: | Taxon | Gene1 | Gene2 ...\n",
    "\n",
    "Creates an enum_<input_filename>, should end with .csv\n",
    "    in the form | Enum_id | Taxon |\n",
    "                |   int   |  str  |\n",
    "\"\"\"\n",
    "def create_enum(ascension_filename):\n",
    "    print(\"Creating enumeration file for \" + ascension_filename)\n",
    "\n",
    "    ascension_file = open(ascension_filename, 'r')\n",
    "    ascension_reader = csv.DictReader(ascension_file)\n",
    "\n",
    "    # Setting the first column to be right - often excel changes this\n",
    "    ascension_fieldnames = ascension_reader.fieldnames\n",
    "    ascension_fieldnames[0] = \"Taxon\"\n",
    "\n",
    "    # Setting the filename and getting the file into a usable form\n",
    "    enum_filename = \"enum_\" + ascension_filename\n",
    "    enum_file = open(enum_filename, 'w')\n",
    "    enum_fieldnames = [\"Enum_id\",\"Taxon\"]\n",
    "    enum_writer = csv.DictWriter(enum_file,fieldnames=enum_fieldnames)\n",
    "\n",
    "    enum_writer.writeheader()\n",
    "\n",
    "    # The enumeration always starts on 1, as is copied in the gene files as well\n",
    "    enum = 1\n",
    "    for ascension_row in ascension_reader:\n",
    "        enum_row = {enum_fieldnames[0]:enum, enum_fieldnames[1]:ascension_row[\"Taxon\"]}\n",
    "        enum_writer.writerow(enum_row)\n",
    "        enum+=1\n",
    "    \n",
    "    ascension_file.close()\n",
    "    enum_file.close()\n",
    "\n",
    "    return enum_filename\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "A function that gets the names of all the fasta files in a given directory\n",
    "\"\"\"\n",
    "def get_fasta_filenames(directory):\n",
    "    # Get all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # Filter only fasta files\n",
    "    return [file for file in files if file.endswith('.fasta')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1 - GET FASTA FILES FROM THE ASCENSION INPUT\n",
    "\n",
    "##### Start at where your Ascension file is\n",
    "\n",
    "The ascension input begins.\n",
    "\n",
    "The below function gets the fasta for a single gene, creating a descriptions file containing the descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "\"\"\"!\n",
    "Takes a set of ascension numbers for the same gene, and creates an unaligned fasta of them\n",
    "\n",
    "/param filename\n",
    "    the name of the output file to be created\n",
    "/param CSVfile\n",
    "    Already loaded into a csv.DictReader. In the format\n",
    "        taxon name , gene 1 , gene 2 , etc\n",
    "        .\n",
    "        .\n",
    "        .\n",
    "    Where the genes are ascension numbers\n",
    "/param gene\n",
    "    the header name for the gene to create a fasta for\n",
    "/param EntrezEmail\n",
    "    an email address for the NCBI, so the US government can track\n",
    "\n",
    "The output is a set of fastas as outputted from the Bio SeqIO with the headers replaced by the taxon names\n",
    "& a file in which the original headers are situated\n",
    " - called filename_data.fasta\n",
    "\n",
    "As well as a descriptions.csv file\n",
    "\"\"\"\n",
    "\n",
    "def fastaFromAscensions(filename,CSVfile,CSVfile_linenum,gene,EntrezEmail):\n",
    "    Entrez.email = EntrezEmail # Telling NCBI who I am\n",
    "\n",
    "    # Setting up checkpoints\n",
    "    chk_count = 0\n",
    "    chk_total = CSVfile_linenum + 3 # + 2 for the checkpoints before going into the loop, + 1 for the one afterwards\n",
    "    chk_count = checkpoint(gene,chk_count,chk_total)\n",
    "\n",
    "    # The genes\n",
    "    listify = []\n",
    "    # The descriptions\n",
    "    dscrptsname = gene + \"_descriptions.csv\"\n",
    "    descptsfile = open(dscrptsname, 'w')\n",
    "    dscrptswriter = csv.writer(descptsfile)\n",
    "    dscrpts = []\n",
    "    enum_id = 0\n",
    "\n",
    "    chk_count = checkpoint(gene,chk_count,chk_total)\n",
    "\n",
    "    for row in CSVfile:\n",
    "        chk_count = checkpoint(gene,chk_count,chk_total)\n",
    "\n",
    "        if (row[gene]!='' and row[gene]!=gene):\n",
    "            # Fetching the fasta from the nucleotide site, then putting it as a SeqRecord type\n",
    "            handle = Entrez.efetch(db=\"nucleotide\", id=row[gene], rettype=\"fasta\", retmode=\"text\")\n",
    "            record_in = SeqIO.read(handle,\"fasta\") # Parses it, then chooses the right one\n",
    "            handle.close()\n",
    "\n",
    "            taxon_name = row[\"Taxon\"].replace(\" \",\"_\")\n",
    "\n",
    "            # Recording the descriptions\n",
    "            dscrpts = [str(enum_id),taxon_name,record_in.id,record_in.description]\n",
    "            dscrptswriter.writerow(dscrpts)\n",
    "\n",
    "            # Creating a clean record with an enumerated id & user-defined description\n",
    "            record_out = SeqIO.SeqRecord(record_in.seq,id = str(enum_id), description = taxon_name)\n",
    "            listify.append(record_out)\n",
    "            \n",
    "        enum_id += 1;\n",
    "    \n",
    "\n",
    "    # Writing the .fasta file\n",
    "    SeqIO.write(listify,filename,\"fasta\")\n",
    "\n",
    "    # Cleaning up\n",
    "    descptsfile.close()\n",
    "    chk_count = checkpoint(gene,chk_count,chk_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through the above function in multiple genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\"\"\"\n",
    "A loop going through the above function for each gene\n",
    "\n",
    "Input - input ascension described above\n",
    "Output - A set of gene files & a .csv for the descriptions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "email = \"rhys.edmunds@yahoo.com\" # TODO will be in the settings.csv\n",
    "\n",
    "# Opening the file into a usable format\n",
    "ascension_filename = \"input_ascension.csv\"\n",
    "file = open(ascension_filename, mode=\"r\")\n",
    "CSVfile = csv.DictReader(file) # DictReader means that the first row is used as monikers for the columns\n",
    "\n",
    "# Creating the enum file\n",
    "enum_filename = create_enum(ascension_filename)\n",
    "\n",
    "# Formatting the csv file's \n",
    "gene_list = CSVfile.fieldnames.copy()\n",
    "if gene_list[0] != \"Taxon\":\n",
    "    gene_list[0] = \"Taxon\"\n",
    "\n",
    "# Getting the gene names\n",
    "fieldnames = gene_list.copy()\n",
    "\n",
    "# Getting only the genes\n",
    "gene_list.remove(\"Taxon\")\n",
    "print(\"GENE LIST: \" + str(gene_list))\n",
    "\n",
    "# Getting the length of the file\n",
    "enum_file = open(enum_filename, 'r')\n",
    "file_length = len(enum_file.readlines())\n",
    "enum_file.close()\n",
    "\n",
    "# Writing the four separate .fasta files in the form\n",
    "\"\"\"\n",
    "><ascension> <taxon>\n",
    "<sequence>\n",
    ".\n",
    ".\n",
    "\"\"\"\n",
    "for gene in gene_list:\n",
    "    # Opening a file & setting the CSV DictReader if the file isn't open already\n",
    "    if file.closed:\n",
    "        file = open(\"input_ascension.csv\", mode=\"r\")\n",
    "        CSVfile = csv.DictReader(file)\n",
    "        print(\"Starting!\")\n",
    "    \n",
    "    # Setting the CSVfile fieldnames\n",
    "    CSVfile.fieldnames = fieldnames\n",
    "\n",
    "    # Processing the gene\n",
    "    print(gene + \" [PROCESSING]\")\n",
    "    filename = str(gene) + \".fasta\"\n",
    "\n",
    "    # TODO TEST WITH .readlines(), make sure it doesn't iterate through\n",
    "    fastaFromAscensions(filename,CSVfile,file_length,gene,email)\n",
    "\n",
    "    # Closing the file\n",
    "    file.close()\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2: RUN THE PASTA ALIGNMENT ON THE FOUR FASTA FILES\n",
    "\n",
    "#### STEP 3: INSPECT THE OUTPUT\n",
    "\n",
    "#### STEP 4: CONCATENATE THE FILES\n",
    "\n",
    "##### Requires the enum file & the aligned, inspected fasta files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Seq import MutableSeq\n",
    "\n",
    "\"\"\"\n",
    "A function that concatenates two genes\n",
    "Genes should have an enumerated id, 0-number of taxa at the beginning\n",
    "& a taxon name\n",
    "e.g.\n",
    "    >12 Siratus_pliciferoides\n",
    "        TCGAGA...\n",
    "\n",
    "CURRENTLY RELIES ON 0 HAVING ALL GENES TODO\n",
    "\n",
    "/param ins - a list of filenames for the relevant fastas\n",
    "/param enum_filename - a filename for the enumerated file for the genes\n",
    "/param out - name of the fasta file to concatenate to, WITHOUT fasta ending\n",
    "\n",
    "writes a fasta file with the enumerated ids, the taxon names & the concatenated genes named\n",
    "writes a gene length file for the genes\n",
    "\"\"\"\n",
    "def concatenateFastas(ins,enum_filename,out):\n",
    "    # Setting up checkpoints\n",
    "    chk_count = 0\n",
    "    chk_total = 3\n",
    "    \n",
    "    chk_count = checkpoint(out,chk_count,chk_total)\n",
    "    \n",
    "    # Getting the enum file\n",
    "    enum_file = open(enum_filename, 'r')\n",
    "    enum_reader = csv.DictReader(enum_file)\n",
    "\n",
    "    # List to write out the sequences\n",
    "    out_list = []\n",
    "\n",
    "    # File that writes the gene length file\n",
    "    gene_len_filename = out[:-6] + \"_gene_lengths.csv\" # filename without the fasta\n",
    "    gene_len_file = open(gene_len_filename,'w')\n",
    "    gene_len_fieldnames = [\"Gene\",\"Length\"]\n",
    "    gene_len_writer = csv.DictWriter(gene_len_file,fieldnames=gene_len_fieldnames)\n",
    "    # For iterating through the genes\n",
    "    gene_num = 0\n",
    "\n",
    "    chk_count = checkpoint(out,chk_count,chk_total)\n",
    "    \n",
    "    for enum_row in enum_reader:\n",
    "        # Creating a sequence & appending the right sequences upon them - the first of a given record only\n",
    "\n",
    "        # Variables for the enum id, in integer & string forms\n",
    "        enum_id = int(enum_row[\"Enum_id\"])\n",
    "        enum_id_str = str(enum_row[\"Enum_id\"])\n",
    "        # log(str_enum_id)\n",
    "        \n",
    "        # The sequence to be appended\n",
    "        temp_sequence = MutableSeq(\"\")\n",
    "\n",
    "        for fasta_name in ins:\n",
    "            if enum_id == 0:\n",
    "                continue\n",
    "            \n",
    "            fasta = SeqIO.index(fasta_name,'fasta')\n",
    "            # for k in fasta.keys():\n",
    "            #     log(k + \": \" + fasta[k].description)\n",
    "\n",
    "            # Getting the genes and their lengths, creating the gene length file\n",
    "            if enum_id == 1:\n",
    "                gene_len_row = {gene_len_fieldnames[0]:fasta_name[:-6],gene_len_fieldnames[1]:len(fasta[enum_id_str].seq)}\n",
    "                gene_num += 1\n",
    "                gene_len_writer.writerow(gene_len_row)\n",
    "            \n",
    "            if enum_id_str in fasta.keys():\n",
    "                # Appending the sequence\n",
    "                temp_sequence = temp_sequence + fasta[enum_id_str].seq\n",
    "            # Adding a None sequence to maintain the correct length if the append wasn't the correct length\n",
    "            else:\n",
    "                zero_sequence = \"-\" * len(fasta['1'].seq)\n",
    "                temp_sequence = temp_sequence + zero_sequence # ASSUMING fasta[0] HAS THE GENE\n",
    "            \n",
    "            fasta.close()\n",
    "            \n",
    "            # Adding to the list for the file to be put out\n",
    "            if (fasta_name == ins[-1]):\n",
    "                #out_list.append(SeqRecord(temp_sequence,enum_row[\"Taxon\"],description=\".\")) # Removed description, was adding a funny point on the end\n",
    "                out_list.append(SeqRecord(temp_sequence,enum_row[\"Taxon\"]))\n",
    "\n",
    "        #out_list.append(SeqRecord(temp_sequence,enum_row[\"Taxon\"]))\n",
    "\n",
    "    chk_count = checkpoint(out,chk_count,chk_total)\n",
    "    \n",
    "    # Writing the file\n",
    "    SeqIO.write(out_list, (out + '.fasta'), 'fasta')\n",
    "\n",
    "    # Closing all the files\n",
    "    gene_len_file.close()\n",
    "    enum_file.close()\n",
    "\n",
    "    chk_count = checkpoint(out,chk_count,chk_total)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above function on all the fastas in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating to concatenated12S16S28SCOI.fasta\n",
      "Creating enumeration file for input_ascension.csv\n",
      "\tconcatenated12S16S28SCOI: checkpoint 0/3\n",
      "\tconcatenated12S16S28SCOI: checkpoint 1/3\n",
      "\tconcatenated12S16S28SCOI: checkpoint 2/3\n",
      "\tconcatenated12S16S28SCOI: checkpoint 3/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nWhat's going wrong - assigning to the one before, the first being assigned to Ergalatax contracta instead of dermomurex neglectus.\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Runs the above code using all the fastas in the current folder as the input\n",
    "\"\"\"\n",
    "\n",
    "fasta_list = get_fasta_filenames('.') # Eventually, this will be set in the folder settings\n",
    "all_fastas = \"\"\n",
    "for f in fasta_list:\n",
    "    all_fastas += f[:-6]\n",
    "\n",
    "filename = \"concatenated\" + all_fastas\n",
    "print(\"Concatenating to \" + filename + \".fasta\")\n",
    "\n",
    "enum_filename = \"enum_input_ascension.csv\"\n",
    "\n",
    "concatenateFastas(fasta_list,enum_filename,filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 5: CONVERT THE FILES TO NEXUS FORMAT FOR MR BAYES\n",
    "\n",
    "##### You may have to remove some ambiguous nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "\"\"\"\n",
    "Function that changes fasta to nexus\n",
    "\n",
    "/param - input_handle: an open file for the fasta that's being read WITHOUT '.fasta'\n",
    "/param - filename: a filename for the given file to be created\n",
    "- Writes a nexus file\n",
    "/return - nexus file of the input file\n",
    "\"\"\"\n",
    "def fasta_to_nexus (fasta_filename, nexus_filename,ambiguous=True):\n",
    "    with open(fasta_filename + '.fasta', \"rU\") as input_handle:\n",
    "        with open(nexus_filename+\".nexus\", \"w\") as output_handle:\n",
    "            records = SeqIO.parse(input_handle, \"fasta\")\n",
    "            records_out = []\n",
    "            for record in records:\n",
    "                if (record.description[-1]=='>'): # Removing ' <unknown description>' occurring on concatenated\n",
    "                    record.description = record.description[:-22]\n",
    "                records_out.append(SeqRecord(seq=record.seq,id=record.description.replace(' ','_'),annotations={\"molecule_type\": \"DNA\"}))\n",
    "            \n",
    "            SeqIO.write(records_out, output_handle, \"nexus\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performing the above function for all fastas in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the above functions\n",
    "gene_list = get_fasta_filenames(\".\")\n",
    "\n",
    "# Removing the file endings \".fasta\", the last 6 characters\n",
    "gene_list = [g[:-6] for g in gene_list]\n",
    "\n",
    "for gene in gene_list:\n",
    "    fasta_to_nexus(gene,gene)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A function to remove ambiguous nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "IUPAC_ambiguous = 'MRWSYKVHDBN' # Global variables\n",
    "\n",
    "\"\"\"\n",
    "Removes IUPAC ambigous characters from a record\n",
    "\n",
    "/param ambig_filename - a fasta\n",
    "/param ambigs - a (const) list of characters that represent the ambiguous characters\n",
    "\n",
    "/return - the same records but with the ambiguous characters replaces by '_'\n",
    "\"\"\"\n",
    "def remove_ambiguous (ambig_filename, ambig_chars = IUPAC_ambiguous, replace_char = '-'):\n",
    "    ambig_file = open(ambig_filename,'r')\n",
    "    unambig_file = open(\"unambiguous_\"+ambig_filename,'w')\n",
    "    for ambig_line in ambig_file.readlines():\n",
    "        # Missing the headers\n",
    "        if (ambig_line[0] == '>'):\n",
    "            unambig_file.write(ambig_line)\n",
    "            continue\n",
    "        \n",
    "        new_line = ambig_line\n",
    "        for ambig_char in ambig_chars:\n",
    "            new_line = new_line.replace(ambig_char,replace_char)\n",
    "\n",
    "        unambig_file.write(new_line)\n",
    "    \n",
    "    return \"unambiguous_\"+ambig_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 6: PERFORM MR BAYES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
